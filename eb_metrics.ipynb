{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import warnings\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from pyplanter import PlantedH5\n",
    "from lib import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"System paths for reading and exporting data. Currently does not support more then one directory at once.\n",
    "\n",
    "input_path (str): Path to directory with *.out data. Requires non-nested directory structure.\n",
    "output_path (str): Path to export directory. Source directory will be created here.\n",
    "file_name (str): Single file export. Leave empty '' for batch (within directory) processing.\n",
    "\"\"\"\n",
    "\n",
    "input_path = '/backup/data/muni/Cells/test_data/'\n",
    "output_path = '/backup/data/muni/Cells/Export/'\n",
    "output_file = 'output2.csv'\n",
    "file_name = None\n",
    "\n",
    "# ----------------------- Notebook global settings -------------------------\n",
    "# Name of peak markers\n",
    "VALID_MARK_LABELS = {'Peak detection'}\n",
    "# Smooth beat series with windows size 1-n, default: 0\n",
    "SMOOTHER = 0\n",
    "# Analysis to use: 'sdnn', 'sdsd', 'rmssd', 'psd', 'poincare', 'sample_entropy'\n",
    "VALID_METHODS = ['sdnn', 'sdsd', 'rmssd', 'psd', 'poincare', 'sample_entropy']\n",
    "\n",
    "VALID_LIM = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Output format settings. Variables `columns`, `custom_channel_names`, `custom_channel_units`, `custom_multipliers`\n",
    "can be specified as empty tuple `()`. In this case default values are inherited from *.ou file. Is specified, all tuples\n",
    "must contain the same number of elements.\n",
    "\n",
    "output_format (str): 'h5' or 'csv' are valid values\n",
    "columns (tuple): Select specific channels only\n",
    "custom_channel_names (tuple): Custom name for each channel\n",
    "custom_channel_units (tuple): New units for each channel\n",
    "custom_multipliers (tuple): Converts each channel to new units/range by using custom multiplier (currently not working for csv)\n",
    "\n",
    "\"\"\"\n",
    "# list files to process\n",
    "file_list = glob(os.path.join(input_path, '**', file_name if file_name else '*.h5'), recursive=True)\n",
    "\n",
    "planter = PlantedH5()\n",
    "metrics = metrics.Metrics(smooth=SMOOTHER)\n",
    "\n",
    "processed_files = list()\n",
    "for file_path in file_list:\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "    print(f'Processing file {file_name}.')\n",
    "\n",
    "    # create file object\n",
    "    planter.open(file_path)    \n",
    "\n",
    "    if 'Marks' not in planter.f_obj:\n",
    "        continue\n",
    "    \n",
    "    # read sampling frequency\n",
    "    fs = planter.f_obj.attrs['Fs'][0]\n",
    "    \n",
    "    # read peak positions and convert it to ms\n",
    "    peak_positions = [mark[0] * (1000 / fs) for mark in planter.f_obj['Marks'] if mark[-1].decode('UTF-8') in VALID_MARK_LABELS]\n",
    "    peak_positions = sorted(peak_positions)\n",
    "    peak_positions = np.array(peak_positions)\n",
    "    nn = np.diff(peak_positions)\n",
    "\n",
    "    # fast check\n",
    "    nn_median = np.median(nn)\n",
    "    below_lim = nn < ((1/VALID_LIM) * nn_median)\n",
    "    above_lim = nn > (VALID_LIM * nn_median)\n",
    "    if (\n",
    "        np.any(below_lim) or\n",
    "        np.any(above_lim)\n",
    "    ):\n",
    "        warnings.warn(\"NN values outside expected interval found. Replaced by median NN.\")\n",
    "        nn[below_lim] = nn_median\n",
    "        nn[above_lim] = nn_median\n",
    "\n",
    "    # compute metrics\n",
    "    metrics.compute(nn, method_list=VALID_METHODS)\n",
    "\n",
    "    processed_files.append(file_name)\n",
    "    \n",
    "    # close file handler\n",
    "    planter.close()\n",
    "\n",
    "# add new column with file ids\n",
    "metrics.results['file_id'] = processed_files\n",
    "\n",
    "if output_path and os.path.isdir(output_path):\n",
    "    metrics.results.to_csv(os.path.join(output_path, output_file))\n",
    "\n",
    "print('Job done!')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "196faf33e2ad606a48f0c32b9066c47740f03692d60ec7f0e49e4f5269939db2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('ml-venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
